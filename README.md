<h1>IBC1.2025.1</h1>

<p>Este es el repositorio oficial de la materia <code>Inferencia Bayesiana Causal 1</code>, 2025, segundo semestre.</p>


<p>El programa en formato PDF se encuentra en <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/programa.pdf">"https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/programa.pdf"</a></p>

<!--
<tr>
  <td width="50%" align="center"><img src="auxiliar/static/ecyt.jpeg" width="250"/></td>
</tr>-->


<h2> Cronograma</h2>


<table>
  <tr>
    <td width="20%" align="center">Unidad</td>
    <td width="20%" align="center">Pre-evaluacion</td>
    <td width="20%" align="center">Bibliografía</td>
    <td width="20%" align="center">Teórica</td>
    <td width="20%" align="center">Práctica</td>
    <td width="20%" align="center">Video</td>
  </tr>
  <tr>
    <td width="20%" align="center">1-modelos</td>
    <td width="20%" align="center"><a href="https://github.com/MetodosBayesianos/IBC1.2025.1/blob/main/enunciados/enunciado1.py">enunciado1.py</a></td>
    <td width="20%" align="center"> - </td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/teorica1-modelos.pdf">teorica1-modelos.pdf</a>
    </td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/practica1.pdf">practica1.pdf</a>
    <br>
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/practica1.py">practica1.py</a>
    <br>
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/NoMontyHall.csv">NoMontyHall.csv</a>
    </td>
    <td width="20%" align="center"> - </td>
  </tr>
  <tr>
    <td width="20%" align="center">2 Inferencia exacta: ventajas.</td>
    <td width="20%" align="center"><a href="https://github.com/MetodosBayesianos/IBC1.2025.1/blob/main/enunciados/enunciado2.py">enunciado2.py</a>
    </td>
    <td width="20%" align="center">
      <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Bishop 2006 (2.3-2.3.6, cap 3)</a>
      <br>
      <a href="https://www.statlearning.com/">ISL (optativo)</a>
    </td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/2-exacta.pdf">teorica2-exacta.pdf</a>
    </td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/practica2.pdf">practica2.pdf</a>
    <br>
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/materiales-practica2.zip">materiales-practica2.zip</a>
    </td>
    <td width="20%" align="center">
    - <!--Video-->
    </td>
  </tr>
  <tr>
    <td width="20%" align="center">3 Sorpresa. Comunicación con la realidad.</td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/blob/main/enunciados/enunciado3.py">enunciado3.py</a>
    </td>
    <td width="20%" align="center">
     <a href="https://github.com/glandfried/biblio/releases/download/teca/mackay2003.pdf">MacKay 2003. (1.1, 2.4-6, 4.1)</a>
      <br>
      <a href="https://homepage.sns.it/marmi/esameIUE/kelly.pdf">Kelly 1956 (intro)</a>
    </td>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/teorica3-dato.pdf">teorica3-dato.pdf</a>
    <td width="20%" align="center">
    <a href="https://github.com/MetodosBayesianos/IBC1.2025.1/releases/download/materiales/practica3.zip">practica3.zip</a>
    </td>
    <td width="20%" align="center">
    - <!--Video-->
    </td>
  </tr>
  <tr>
    <td width="20%" align="center">4 Flujo de inferencia</td>
    <td width="20%" align="center">
    - <!--Pre-evaluación -->
    </td>
    <td width="20%" align="center">
     <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Bishop 2006 (8.1, 8.2, 8.4)</a>
     <br>
     <a href="https://www.bradyneal.com/Introduction_to_Causal_Inference-Dec17_2020-Neal.pdf">Neal 2020. (Cap 1 y 3)</a>
     <br>
     <a href="https://github.com/glandfried/biblio/releases/download/teca/kschischang2001.pdf">Kschischang 2001 (optativo)</a>
    </td>
    <td width="20%" align="center">
    - <!--Teórica-->
    <td width="20%" align="center">
    - <!--Practica-->
    </td>
    <td width="20%" align="center">
    - <!--Video-->
    </td>
  </tr>


<h2> Materia <code>Inferencia Bayesiana Causal 1</code>. (IBC1.2025.1)</h2>

La materia <code>Inferencia Bayesiana Causal 1</code> se imparte como optativa de forma paralela en las licenciaturas de ciencias de datos de la Escuela de Ciencia y Tecnología de la UNSAM.

<br>

<table>
  <tr>
    <td width="50%" align="center"><img src="https://raw.githubusercontent.com/glandfried/images/master/logos/ecyt.jpeg" width="250"/></td>
    <td width="50%" align="center"><img src="https://raw.githubusercontent.com/glandfried/images/master/logos/UNSAM_blanco.png" width="250"/></td>
  </tr>
  <tr>
    <td width="50%" align="center"><b>Campus Migueletes - EscuelaCyT</b></td>
    <td width="50%" align="center"><b>Universidad Nacional de San Martín - Argentina</b></td>
  </tr>
</table>

<h2>Objetivos.</h2>

<p>
Esta materia está enfocada en la evaluación de argumentos causales alternativos mediante la (aproximación a) la aplicación estricta de las reglas de la probabilidad, el sistema de razonamiento en contextos de incertidumbre. La materia tiene por principal objetivo revisar los métodos desarrollados en las últimas décadas para:

<ul>
<li> Especificar matemáticamente los argumentos causales expresados en lenguaje natural mediante métodos gráficos intuitivos</li>
<li> Precisar cómo la estructura causal influye en el flujo de inferencia entre las variables del modelo.</li>
<li> Identificar el efecto causal entre variables de un modelo causal en base de datos observacionales (sin intervenciones).</li>
<li> Diseñar experimentos que permitan evaluar teorías causales alternativos</li>
<li> Seleccionar decisiones óptimas en ciclos de acción-percepción con una naturaleza oculta (simulada).</li>
</ul>

El problema real detrás de este problema de conocimiento es responder preguntas esenciales como **¿Qué acciones generan bienestar?**.

</p>

<h2>Marco Conceptual</h2>

<p>

<strong>Definición de Inferencia</strong>. Las "verdades" son proposiciones válidas para todas las personas. Las ciencias con datos deben validar sus proposiciones (hipótesis) en sistemas naturales abiertos. ¿Tiene sentido hablar de "verdad" si justamente tenemos incertidumbre respecto de su valor real? Al menos podemos evitar mentir: no afirmar más de lo que se sabe (maximizando incertidumbre) sin ocultar todo aquello que sí se sabe (dada la información disponible o restricciones).

<br>

<strong>Definición de Bayes</strong>. Evaluación de todo el espacio de hipótesis mediante la (aproximación a la) aplicación estricta de las reglas de la probabilidad: preservar la creencia previa que sigue siendo compatible con los datos (regla del producto) y predecir con la contribución de todas las hipótesis (regla de la suma). Debido al costo computacional de las reglas de la probabilidad, durante el siglo 20 propusieron una gran cantidad criterios arbitrarios de selección de hipótesis, que genera siempre efectos secundarios indeseados como ocurre con el overfitting. Afortunadamente, la aplicación estricta de las reglas de la probabilidad no exhiben estos problemas. Si lo hicieran, no tendríamos aún un sistema de razonamiento para contexto de incertidumbre.

<br>

<strong>Definición de Causal</strong>. El problema real de todo organismo vivo es orientar el ciclo de acción-percepción con la naturaleza en favor de su reproducción, supervivencia y bienestar. Los problemas del conocimiento científico obtienen su relevancia y jerarquía de los objetivos que persigue alcanzar. Luego de una percepción evaluamos los argumentos causales alternativos maximizando la incertidumbre dada la información disponible, y antes de actuar seleccionamos la acción minimizando la incertidumbre esperada en relación al objetivo que perseguimos.

</p>

<h2>Programa</h2>
<!--
<h3>Primera parte</h3>-->

<ul>
<li>Semana 1. Introducción a la especificación y evaluación de argumentos causales</li>
<li>Semana 2. Inferencia exacta. Modelos conjugados. Regresión lineal bayesiana.</li>
<li> Semana 3. Teorías causales (o estructuras dinámicas), intervenciones y flujo de inferencia.</li>
<li>Semana 4. Sorpresa: el problema de la comunicación con la realidad</li>
<li>Semana 5. Estrategias para la estimación pasiva de efectos causales.</li>
<li>Semana 6. Buenos, neutrales y malos controles.</li>
<li>Semana 7. La utilidad de los controles neutrales: efectos causales heterogéneos.</li>
<li>Semana 8. Una alternativa ante controles no observables: variables instrumentales.</li>
<li>Semana 9. Repensando la regresión lineal: Matching.</li>
<li>Semana 10. Demasiados controles?: Inverse Probability Weighting</li>
<li>Semana 11. Estimador doblemente robusto: regresión + IPW.</li>
<li>Semana 12. Series temporales y modelos de historia completa.</li>
<li>Semana 13. Otra alternativa ante controles no observables: Paneles y efectos fijos.</li>
<li>Semana 14. Eliminando tendencias: Diferencia en diferencias y controles basados en modelos</li> generativos.
<li>Semana 15. Acción-percepción: el problema de la interacción con la realidad</li>
<li>Semana 16. Trabajo final</li>
</ul>

